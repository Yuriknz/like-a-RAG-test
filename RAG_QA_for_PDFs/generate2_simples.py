"""
ğŸ” GERADOR DE EMBEDDINGS (SIMPLIFICADO)
======================================
Gera embeddings do Markdown para busca
"""

import json
import re
from pathlib import Path
import tiktoken
import ollama

# ConfiguraÃ§Ã£o
MARKDOWN_FILE = "../mdPath/pdf2.md"
OUTPUT_FILE = "../embeddings/embeddings.json"
EMBEDDING_MODEL = "nomic-embed-text:latest"
CHUNK_SIZE = 512
OVERLAP = 128

def test_ollama():
    """Testa conexÃ£o com Ollama."""
    try:
        ollama.embeddings(model=EMBEDDING_MODEL, prompt="teste")
        print("âœ… Ollama conectado")
        return True
    except Exception as e:
        print(f"âŒ Erro Ollama: {e}")
        print(f"ğŸ’¡ Execute: ollama pull {EMBEDDING_MODEL}")
        return False

def chunk_text(text):
    """Divide texto em chunks."""
    tokenizer = tiktoken.get_encoding("cl100k_base")
    
    # Dividir por seÃ§Ãµes (##)
    sections = re.split(r'\n## ', text)
    chunks = []
    
    for i, section in enumerate(sections):
        if not section.strip():
            continue
            
        # TÃ­tulo da seÃ§Ã£o
        lines = section.split('\n')
        title = lines[0].replace('## ', '').strip()
        content = '\n'.join(lines[1:]).strip()
        
        if not content:
            continue
        
        # Dividir seÃ§Ã£o em parÃ¡grafos
        paragraphs = [p.strip() for p in content.split('\n\n') if p.strip()]
        
        for j, paragraph in enumerate(paragraphs):
            # Verificar se Ã© tabela
            is_table = '|' in paragraph and paragraph.count('|') > 2
            
            # Contexto completo
            if is_table:
                contextual_content = f"SeÃ§Ã£o: {title}. Tabela: {paragraph}"
                chunk_type = "table_row"
            else:
                contextual_content = f"SeÃ§Ã£o: {title}. {paragraph}"
                chunk_type = "text_chunk"
            
            chunks.append({
                'id': f"chunk_{i}_{j}",
                'content': paragraph,
                'contextual_content': contextual_content,
                'type': chunk_type,
                'section_title': title,
                'embedding': None  # SerÃ¡ preenchido depois
            })
    
    print(f"âœ… Texto dividido em {len(chunks)} chunks")
    return chunks

def generate_embeddings(chunks):
    """Gera embeddings para os chunks."""
    print("ğŸ”„ Gerando embeddings...")
    
    for i, chunk in enumerate(chunks):
        try:
            response = ollama.embeddings(
                model=EMBEDDING_MODEL,
                prompt=chunk['contextual_content']
            )
            chunk['embedding'] = response['embedding']
            
            if (i + 1) % 50 == 0:
                print(f"   Processados: {i + 1}/{len(chunks)}")
                
        except Exception as e:
            print(f"âŒ Erro no chunk {i}: {e}")
            return None
    
    print("âœ… Embeddings gerados")
    return chunks

def main():
    """FunÃ§Ã£o principal."""
    print("ğŸ” GERADOR DE EMBEDDINGS")
    print("=" * 40)
    
    # Verificar arquivo
    markdown_path = Path(MARKDOWN_FILE)
    if not markdown_path.exists():
        print(f"âŒ Arquivo nÃ£o encontrado: {markdown_path}")
        print("ğŸ’¡ Execute primeiro: python doclingpdf_simples.py")
        return
    
    # Testar Ollama
    if not test_ollama():
        return
    
    # Carregar e processar texto
    print(f"ğŸ“– Carregando: {markdown_path}")
    with open(markdown_path, 'r', encoding='utf-8') as f:
        text = f.read()
    
    print(f"ğŸ“Š Tamanho: {len(text)} caracteres")
    
    # Dividir em chunks
    chunks = chunk_text(text)
    
    # Gerar embeddings
    chunks_with_embeddings = generate_embeddings(chunks)
    if not chunks_with_embeddings:
        return
    
    # Salvar
    output_path = Path(OUTPUT_FILE)
    output_path.parent.mkdir(parents=True, exist_ok=True)
    
    with open(output_path, 'w', encoding='utf-8') as f:
        json.dump(chunks_with_embeddings, f, ensure_ascii=False, indent=2)
    
    print(f"âœ… Embeddings salvos: {output_path}")
    print(f"ğŸ“Š Total de embeddings: {len(chunks_with_embeddings)}")
    print("\nğŸ‰ Pronto!")
    print("ğŸ’¡ PrÃ³ximo passo: python ollama_ask2_simples.py")

if __name__ == "__main__":
    main()
